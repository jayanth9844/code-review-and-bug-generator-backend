{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNnInSuc9Qro",
        "outputId": "7cde2876-d9bb-4ca9-d8f8-0bb8d5921d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.3.5)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.12.3)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.38.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.4)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.29.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9319ozYU9WP5",
        "outputId": "f42e7d24-9ecc-433a-a1c9-f139ba7ded2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.1.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.47)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Installed langchain-community.\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community\n",
        "print(\"Installed langchain-community.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MoRu3b-A-BBH",
        "outputId": "854248ee-20f3-4c9c-8b26-8d57fdfe5f85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: google-generativeai 0.8.5\n",
            "Uninstalling google-generativeai-0.8.5:\n",
            "  Successfully uninstalled google-generativeai-0.8.5\n",
            "Found existing installation: langchain-google-genai 3.2.0\n",
            "Uninstalling langchain-google-genai-3.2.0:\n",
            "  Successfully uninstalled langchain-google-genai-3.2.0\n",
            "Found existing installation: google-ai-generativelanguage 0.9.0\n",
            "Uninstalling google-ai-generativelanguage-0.9.0:\n",
            "  Successfully uninstalled google-ai-generativelanguage-0.9.0\n",
            "Collecting google-generativeai\n",
            "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.5)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
            "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai\n",
            "Successfully installed google-ai-generativelanguage-0.6.15 google-generativeai-0.8.5\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "414f0154b00b4cbc9e418c19130b092f",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (2.12.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.43.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.4.47)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-google-genai) (1.3.1)\n",
            "Using cached langchain_google_genai-3.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.9.0 langchain-google-genai-3.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4d2982fb575c4c09b3c1aa5b2371ab44",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall -y google-generativeai langchain-google-genai google-ai-generativelanguage\n",
        "!pip install --upgrade google-generativeai\n",
        "!pip install --upgrade langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP67CEhP9pJF",
        "outputId": "78b6ad70-034c-4a88-f877-ccfd18a2134a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function 'initialize_vector_store_and_embeddings' defined.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "\n",
        "def initialize_vector_store_and_embeddings():\n",
        "  \"\"\"\n",
        "  Initializes a Chroma vector store and a SentenceTransformer embedding model.\n",
        "\n",
        "  Returns:\n",
        "    tuple: A tuple containing the embedding model and the Chroma vector store.\n",
        "  \"\"\"\n",
        "  # Create an instance of SentenceTransformerEmbeddings\n",
        "  # Using 'all-MiniLM-L6-v2' as the model name as specified.\n",
        "  embedding_model = SentenceTransformerEmbeddings(model_name='all-MiniLM-L6-v2')\n",
        "\n",
        "  # Create an in-memory instance of Chroma using the embedding model\n",
        "  vector_store = Chroma(embedding_function=embedding_model)\n",
        "\n",
        "  return embedding_model, vector_store\n",
        "\n",
        "print(\"Function 'initialize_vector_store_and_embeddings' defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNweKEyh9q0B",
        "outputId": "9c91b21a-6211-4b03-833f-47989a63d7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function 'load_and_index_code' defined.\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_core.documents import Document\n",
        "import os\n",
        "\n",
        "def load_and_index_code(code_input, embedding_model, vector_store):\n",
        "  \"\"\"\n",
        "  Loads code from a directory or a list of snippets, splits them into chunks,\n",
        "  embeds them, and adds them to the Chroma vector store.\n",
        "\n",
        "  Args:\n",
        "    code_input (str or list): A directory path (string) or a list of code snippets (list of strings).\n",
        "    embedding_model: The SentenceTransformerEmbeddings model.\n",
        "    vector_store: The Chroma vector store instance.\n",
        "\n",
        "  Returns:\n",
        "    str: A confirmation message indicating success.\n",
        "  \"\"\"\n",
        "  documents = []\n",
        "\n",
        "  if isinstance(code_input, str) and os.path.isdir(code_input):\n",
        "    # Load from directory if code_input is a directory path\n",
        "    loader = DirectoryLoader(code_input, glob=\"**/*.py\")\n",
        "    loaded_docs = loader.load()\n",
        "    for doc in loaded_docs:\n",
        "      documents.append(Document(page_content=doc.page_content, metadata=doc.metadata))\n",
        "  elif isinstance(code_input, list):\n",
        "    # Create documents from a list of code snippets\n",
        "    for snippet in code_input:\n",
        "      documents.append(Document(page_content=snippet))\n",
        "  else:\n",
        "    raise ValueError(\"code_input must be a directory path (string) or a list of code snippets (list).\")\n",
        "\n",
        "  # Initialize RecursiveCharacterTextSplitter\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "  # Split documents into chunks\n",
        "  code_chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "  # Add code chunks to the vector store\n",
        "  vector_store.add_documents(code_chunks)\n",
        "\n",
        "  return \"Code loaded, chunked, embedded, and added to the vector store successfully.\"\n",
        "\n",
        "print(\"Function 'load_and_index_code' defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA-yL5el9uJa",
        "outputId": "683ca20e-7792-41ff-d4da-527b10d88dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function 'analyze_code' updated for RAG integration.\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import json\n",
        "\n",
        "# Re-defining api_key for this cell's scope to resolve NameError\n",
        "api_key = 'AIzaSyAlYZ1Jc__9nfT3opMVaq_lNURYJXrK8dM' # Directly assigning your API key.\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "def analyze_code(query: str, embedding_model, vector_store) -> str:\n",
        "  \"\"\"\n",
        "  Analyzes code using the Gemini API via LangChain, retrieving relevant snippets from a vector store based on a query.\n",
        "\n",
        "  Args:\n",
        "    query (str): The natural language query describing the code analysis needed.\n",
        "    embedding_model: The SentenceTransformerEmbeddings model to embed the query.\n",
        "    vector_store: The Chroma vector store instance to retrieve relevant code snippets.\n",
        "\n",
        "  Returns:\n",
        "    str: A JSON string containing the analysis results.\n",
        "  \"\"\"\n",
        "\n",
        "  # 1. Create an embedding for the query\n",
        "  query_embedding = embedding_model.embed_query(query)\n",
        "\n",
        "  # 2. Retrieve top N relevant code snippets from the vector store\n",
        "  # We'll retrieve top 5 for a good balance of context and conciseness.\n",
        "  relevant_docs = vector_store.similarity_search_by_vector(query_embedding, k=5)\n",
        "\n",
        "  # 3. Concatenate the page_content of the retrieved documents\n",
        "  # This combined code will be what Gemini analyzes.\n",
        "  combined_code_for_analysis = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", google_api_key=api_key)\n",
        "\n",
        "  prompt_template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"You are a helpful assistant that analyzes code for potential issues and returns the analysis in a structured JSON format.\"),\n",
        "      (\"human\", \"Analyze the following code snippet for potential issues. \\nProvide the analysis in a structured JSON format, including 'title', 'type', 'severity' (e.g., 'Low', 'Medium', 'High', 'Critical'), 'lineNumber', 'description', and 'suggestedFix' for each issue found.\\n\\nCode:\\n```python\\n{code_snippet}\\n```\\n\\nExample JSON format for issues:\\n{{\\\"issues\\\": [{{\\\"title\\\": \\\"Issue Title\\\", \\\"type\\\": \\\"Bug\\\", \\\"severity\\\": \\\"High\\\", \\\"lineNumber\\\": 10, \\\"description\\\": \\\"Detailed description of the issue.\\\", \\\"suggestedFix\\\": \\\"Recommended fix for the issue.\\\"}}]}}\")\n",
        "  ])\n",
        "\n",
        "  output_parser = StrOutputParser()\n",
        "\n",
        "  chain = prompt_template | llm | output_parser\n",
        "\n",
        "  # Pass the combined code from RAG to the Gemini API\n",
        "  response = chain.invoke({\"code_snippet\": combined_code_for_analysis})\n",
        "\n",
        "  # Remove markdown code block if present in the response\n",
        "  if response.startswith('```json') and response.endswith('```'):\n",
        "    response = response.replace('```json\\n', '', 1)\n",
        "    response = response.replace('\\n```', '', 1)\n",
        "\n",
        "  try:\n",
        "    parsed_response = json.loads(response)\n",
        "    return parsed_response\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Error: Invalid JSON string received from model: {response}\")\n",
        "    return {\"issues\": []}\n",
        "\n",
        "print(\"Function 'analyze_code' updated for RAG integration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVaIl9h1-L5n",
        "outputId": "d3fe6c1e-c409-4be0-803b-f47d455b71a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function 'get_code_metrics' updated for RAG integration.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def get_code_metrics(query: str, embedding_model, vector_store) -> dict:\n",
        "  \"\"\"\n",
        "  Calculates summary metrics and issue distribution by directly querying the Gemini API,\n",
        "  retrieving relevant snippets from a vector store based on a query.\n",
        "\n",
        "  Args:\n",
        "    query (str): The natural language query describing the code analysis needed.\n",
        "    embedding_model: The SentenceTransformerEmbeddings model to embed the query.\n",
        "    vector_store: The Chroma vector store instance to retrieve relevant code snippets.\n",
        "\n",
        "  Returns:\n",
        "    dict: A dictionary containing 'summary_metrics' and 'issue_distribution' from Gemini.\n",
        "  \"\"\"\n",
        "  genai.configure(api_key=api_key)\n",
        "  llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", google_api_key=api_key)\n",
        "\n",
        "  # 1. Create an embedding for the query\n",
        "  query_embedding = embedding_model.embed_query(query)\n",
        "\n",
        "  # 2. Retrieve top N relevant code snippets from the vector store\n",
        "  # We'll retrieve top 5 for a good balance of context and conciseness.\n",
        "  relevant_docs = vector_store.similarity_search_by_vector(query_embedding, k=5)\n",
        "\n",
        "  # 3. Concatenate the page_content of the retrieved documents\n",
        "  # This combined code will be what Gemini analyzes.\n",
        "  combined_code_for_metrics = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "  prompt_template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"You are a helpful assistant that analyzes code and provides summary metrics and issue distribution in a structured JSON format.\"),\n",
        "      (\"human\", \"\"\"Analyze the following code snippet and provide the analysis in a structured JSON format. I need two main sections: 'summary_metrics' and 'issue_distribution'.\\n\\nFor 'summary_metrics', include:\\n- 'code_quality_score' (an integer from 0-100 where higher is better)\\n- 'security_rating' (an integer from 0-100 where higher is better)\\n- 'bug_density' (count of bugs/runtime errors)\\n- 'critical_issue_count' (count of critical severity issues)\\n\\nFor 'issue_distribution', include:\\n- 'security_vulnerabilities' (count of security/vulnerability issues)\\n- 'code_smells' (count of code smell issues)\\n- 'best_practices' (count of best practice violations, if any)\\n- 'performance_issues' (count of performance-related issues, if any)\\n\\nEnsure the output is a single JSON object. Here's an example of the desired JSON format:\\n```json\\n{{\\n  \"summary_metrics\": {{\\n    \"code_quality_score\": 85,\\n    \"security_rating\": 90,\\n    \"bug_density\": 1,\\n    \"critical_issue_count\": 0\\n  }},\\n  \"issue_distribution\": {{\\n    \"security_vulnerabilities\": 0,\\n    \"code_smells\": 2,\\n    \"best_practices\": 1,\\n    \"performance_issues\": 0\\n  }}\\n}}\\n```\\n\\nCode:\\n```python\\n{code_snippet}\\n```\"\"\")\n",
        "  ])\n",
        "\n",
        "  output_parser = StrOutputParser()\n",
        "\n",
        "  chain = prompt_template | llm | output_parser\n",
        "\n",
        "  response = chain.invoke({\"code_snippet\": combined_code_for_metrics})\n",
        "\n",
        "  # Remove markdown code block if present in the response\n",
        "  if response.startswith('```json') and response.endswith('```'):\n",
        "    response = response.replace('```json\\n', '', 1)\n",
        "    response = response.replace('\\n```', '', 1)\n",
        "\n",
        "  try:\n",
        "    parsed_response = json.loads(response)\n",
        "    return parsed_response\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Error: Invalid JSON string received from model: {response}\")\n",
        "    return {\n",
        "        \"summary_metrics\": {},\n",
        "        \"issue_distribution\": {}\n",
        "    }\n",
        "\n",
        "print(\"Function 'get_code_metrics' updated for RAG integration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D_hA9629x9m",
        "outputId": "1337e6ba-226d-421d-d2bf-2fd8f1346302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Function 'inject_bugs' updated for RAG integration.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import google.generativeai as genai\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def inject_bugs(query: str, embedding_model, vector_store, bug_type: str, severity_level: int, num_bugs: int) -> dict:\n",
        "  \"\"\"\n",
        "  Injects specified types and number of bugs into a given code snippet, retrieved via RAG, using the Gemini API.\n",
        "\n",
        "  Args:\n",
        "    query (str): The natural language query describing the code context for bug injection.\n",
        "    embedding_model: The SentenceTransformerEmbeddings model to embed the query.\n",
        "    vector_store: The Chroma vector store instance to retrieve relevant code snippets.\n",
        "    bug_type (str): The type of bug to inject (e.g., 'SQL Injection', 'Division by Zero').\n",
        "    severity_level (int): The severity level of the bugs (e.g., 1 for low, 5 for critical).\n",
        "    num_bugs (int): The number of bugs to inject.\n",
        "\n",
        "  Returns:\n",
        "    dict: A dictionary containing the modified code with injected bugs and details\n",
        "          about the injected bugs (e.g., their locations, types, and severities).\n",
        "  \"\"\"\n",
        "  genai.configure(api_key=api_key)\n",
        "  llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", google_api_key=api_key)\n",
        "\n",
        "  # 1. Create an embedding for the query\n",
        "  query_embedding = embedding_model.embed_query(query)\n",
        "\n",
        "  # 2. Retrieve top N relevant code snippets from the vector store\n",
        "  # We'll retrieve top 5 for a good balance of context and conciseness.\n",
        "  relevant_docs = vector_store.similarity_search_by_vector(query_embedding, k=5)\n",
        "\n",
        "  # 3. Concatenate the page_content of the retrieved documents\n",
        "  # This combined code will be what Gemini injects bugs into.\n",
        "  combined_code_for_injection = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "\n",
        "  prompt_template = ChatPromptTemplate.from_messages([\n",
        "      (\"system\", \"You are a helpful assistant that injects bugs into code based on given parameters and returns the modified code and bug details in JSON format.\"),\n",
        "      (\"human\", \"\"\"Inject {num_bugs} bugs of type '{bug_type}' with severity level {severity_level} into the following Python code snippet.\n",
        "Provide the output in a structured JSON format with two keys: 'buggy_code' (containing the full modified code) and 'bugs_injected' (an array of objects, where each object describes an injected bug with 'type', 'line_number', and 'description').\n",
        "\n",
        "Code:\n",
        "```python\n",
        "{code_snippet}\n",
        "```\n",
        "\n",
        "Example JSON format:\n",
        "{{\n",
        "  \"buggy_code\": \"def example_function():\\n    # Some example code without further template variables\\n    return 0\",\n",
        "  \"bugs_injected\": [\n",
        "    {{\n",
        "      \"type\": \"{bug_type}\", \"line_number\": 2, \"description\": \"Description of the injected bug.\"\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\"\"\")\n",
        "  ])\n",
        "\n",
        "  output_parser = StrOutputParser()\n",
        "\n",
        "  chain = prompt_template | llm | output_parser\n",
        "\n",
        "  response = chain.invoke({\n",
        "      \"code_snippet\": combined_code_for_injection,\n",
        "      \"num_bugs\": num_bugs,\n",
        "      \"bug_type\": bug_type,\n",
        "      \"severity_level\": severity_level\n",
        "  })\n",
        "\n",
        "  # Remove markdown code block if present in the response\n",
        "  if response.startswith('```json') and response.endswith('```'):\n",
        "    response = response.replace('```json\\n', '', 1)\n",
        "    response = response.replace('\\n```', '', 1)\n",
        "\n",
        "  try:\n",
        "    parsed_response = json.loads(response)\n",
        "    return parsed_response\n",
        "  except json.JSONDecodeError:\n",
        "    print(f\"Error: Invalid JSON string received from model: {response}\")\n",
        "    return {\n",
        "        \"buggy_code\": combined_code_for_injection, # Return original code retrieved from RAG on error\n",
        "        \"bugs_injected\": []\n",
        "    }\n",
        "\n",
        "print(\"Function 'inject_bugs' updated for RAG integration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG1yptiS-nd6",
        "outputId": "8d379bf5-5573-4f24-9abf-5af70418e9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG system initialized.\n",
            "Long sample code loaded into vector store.\n",
            "\n",
            "=== Testing analyze_code ===\n",
            "\n",
            "--- Analysis Result (long_sample_code) ---\n",
            "\n",
            "{\n",
            "  \"issues\": [\n",
            "    {\n",
            "      \"title\": \"Storing Passwords in Plain Text\",\n",
            "      \"type\": \"Security\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"lineNumber\": 161,\n",
            "      \"description\": \"The `add_user` method stores user passwords directly in the database without any hashing. This is a major security risk, as a database breach would expose all user passwords.\",\n",
            "      \"suggestedFix\": \"Hash passwords using a strong, salted hashing algorithm like Argon2, scrypt, or bcrypt before storing them. Use a library like `passlib` for robust password handling.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"SQL Injection Vulnerability\",\n",
            "      \"type\": \"Security\",\n",
            "      \"severity\": \"Critical\",\n",
            "      \"lineNumber\": 161,\n",
            "      \"description\": \"The database queries in `add_user` (line 161) and `get_user` (line 166) are constructed using f-strings, which directly embeds user input into the SQL statement. This makes the application vulnerable to SQL injection attacks, allowing an attacker to manipulate the database.\",\n",
            "      \"suggestedFix\": \"Use parameterized queries (placeholders) to safely pass data to the database driver. For example, replace `f\\\"SELECT * FROM users WHERE name = '{username}'\\\"` with `self.cursor.execute(\\\"SELECT * FROM users WHERE name = ?\\\", (username,))`.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Race Condition on Shared Cache\",\n",
            "      \"type\": \"Bug\",\n",
            "      \"severity\": \"High\",\n",
            "      \"lineNumber\": 171,\n",
            "      \"description\": \"Multiple threads concurrently call `manager.cache_user`, which modifies the shared `self.cache` dictionary. This operation is not atomic and lacks synchronization, creating a race condition that can lead to data corruption or an inconsistent cache state.\",\n",
            "      \"suggestedFix\": \"Introduce a `threading.Lock` in the `UserManager` class. Acquire the lock before modifying the cache and release it afterward, for instance by using a `with` statement: `with self.cache_lock: self.cache[username] = user`.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Division by Zero Error\",\n",
            "      \"type\": \"Bug\",\n",
            "      \"severity\": \"High\",\n",
            "      \"lineNumber\": 141,\n",
            "      \"description\": \"The code attempts to divide 10 by 0, which will always raise a `ZeroDivisionError` and cause the program to crash.\",\n",
            "      \"suggestedFix\": \"Add a check to ensure the divisor is not zero before performing the division, or wrap the operation in a `try...except ZeroDivisionError` block to handle the exception gracefully.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Syntax Error in Print Statement\",\n",
            "      \"type\": \"Bug\",\n",
            "      \"severity\": \"High\",\n",
            "      \"lineNumber\": 139,\n",
            "      \"description\": \"The line `print(\\\"Fibonacci(30):\\\"), heavy_computation(30))` is syntactically incorrect in Python 3 due to a misplaced parenthesis and will prevent the script from running.\",\n",
            "      \"suggestedFix\": \"Correct the syntax to properly call the print function with both arguments: `print(\\\"Fibonacci(30):\\\", heavy_computation(30))`.\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Inefficient Recursive Algorithm\",\n",
            "      \"type\": \"Performance\",\n",
            "      \"severity\": \"Medium\",\n",
            "      \"lineNumber\": 8,\n",
            "      \"description\": \"The `heavy_computation` function calculates Fibonacci numbers using a naive recursive approach. This results in an exponential time complexity (O(2^n)) due to redundant calculations, causing a significant performance bottleneck for even moderately large inputs.\",\n",
            "      \"suggestedFix\": \"Implement a more efficient algorithm, such as an iterative approach or recursion with memoization (e.g., using `@functools.lru_cache`), to achieve a linear time complexity (O(n)).\"\n",
            "    },\n",
            "    {\n",
            "      \"title\": \"Unbounded Cache Growth (Potential Memory Leak)\",\n",
            "      \"type\": \"Performance\",\n",
            "      \"severity\": \"Low\",\n",
            "      \"lineNumber\": 171,\n",
            "      \"description\": \"The `self.cache` dictionary in the `UserManager` class grows indefinitely as new users are cached. There is no mechanism to evict old or unused entries, which can lead to a memory leak in a long-running application.\",\n",
            "      \"suggestedFix\": \"Implement a cache eviction policy, such as Least Recently Used (LRU) or a simple size limit, to control the growth of the cache. Using a library like `cachetools` or Python's `functools.lru_cache` can simplify this.\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "=== Testing get_code_metrics ===\n",
            "\n",
            "--- Metrics Result (long_sample_code) ---\n",
            "\n",
            "{\n",
            "  \"summary_metrics\": {\n",
            "    \"code_quality_score\": 10,\n",
            "    \"security_rating\": 5,\n",
            "    \"bug_density\": 2,\n",
            "    \"critical_issue_count\": 5\n",
            "  },\n",
            "  \"issue_distribution\": {\n",
            "    \"security_vulnerabilities\": 3,\n",
            "    \"code_smells\": 2,\n",
            "    \"best_practices\": 0,\n",
            "    \"performance_issues\": 1\n",
            "  }\n",
            "}\n",
            "\n",
            "=== Testing inject_bugs ===\n",
            "\n",
            "--- Bug Injection Result (long_sample_code) ---\n",
            "\n",
            "Buggy Code:\n",
            "```python\n",
            "import sqlite3\n",
            "import threading\n",
            "import time\n",
            "import os\n",
            "import pickle\n",
            "import base64\n",
            "\n",
            "class UserManager:\n",
            "    def __init__(self, db_path=\"users.db\"):\n",
            "        self.conn = sqlite3.connect(db_path, check_same_thread=False)\n",
            "        self.cursor = self.conn.cursor()\n",
            "        self.cursor.execute(\"CREATE TABLE IF NOT EXISTS users (name TEXT, password TEXT)\")\n",
            "        self.cache = {}\n",
            "\n",
            "    def add_user(self, username, password):\n",
            "        # Logic error: storing password in plain text\n",
            "        self.cursor.execute(f\"INSERT INTO users (name, password) VALUES ('{username}', '{password}')\")\n",
            "        self.conn.commit()\n",
            "\n",
            "    def get_user(self, username):\n",
            "        # Security vulnerability: SQL injection risk\n",
            "        query = f\"SELECT * FROM users WHERE name = '{username}'\"\n",
            "        self.cursor.execute(query)\n",
            "        return self.cursor.fetchall()\n",
            "\n",
            "    def cache_user(self, username):\n",
            "        # Potential memory leak: cache never cleared\n",
            "        user = self.get_user(username)\n",
            "        self.cache[username] = user\n",
            "\n",
            "    def load_user_profile(self, profile_data):\n",
            "        # BUG: Insecure Deserialization of data from an untrusted source.\n",
            "        deserialized_data = pickle.loads(base64.b64decode(profile_data))\n",
            "        print(f\"Loaded profile: {deserialized_data}\")\n",
            "        return deserialized_data\n",
            "\n",
            "    def run_system_check(self, hostname):\n",
            "        # BUG: Command Injection by using user input directly in a system call.\n",
            "        print(f\"Pinging {hostname}...\")\n",
            "        os.system(f\"ping -c 1 {hostname}\")\n",
            "\n",
            "\n",
            "def worker_task(manager, username):\n",
            "    # Concurrency bug: race condition on shared cache\n",
            "    for _ in range(1000):\n",
            "        manager.cache_user(username)\n",
            "\n",
            "def heavy_computation(n):\n",
            "    # Performance issue: inefficient recursion\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    return heavy_computation(n-1) + heavy_computation(n-2)\n",
            "\n",
            "def main():\n",
            "    if os.path.exists(\"users.db\"): # Clean up for fresh run\n",
            "        os.remove(\"users.db\")\n",
            "        \n",
            "    manager = UserManager()\n",
            "    manager.add_user(\"Alice\", \"password123\")\n",
            "    manager.add_user(\"Bob\", \"hunter2\")\n",
            "\n",
            "    threads = []\n",
            "    for name in [\"Alice\", \"Bob\"]:\n",
            "        t = threading.Thread(target=worker_task, args=(manager, name))\n",
            "        threads.append(t)\n",
            "        t.start()\n",
            "\n",
            "    for t in threads:\n",
            "        t.join()\n",
            "\n",
            "    print(f\"Fibonacci(30): {heavy_computation(30)}\")\n",
            "\n",
            "    try:\n",
            "        print(\"Divide:\", 10 / 0)\n",
            "    except ZeroDivisionError as e:\n",
            "        print(f\"Caught expected error: {e}\")\n",
            "\n",
            "    # Trigger Insecure Deserialization vulnerability\n",
            "    # This payload, when deserialized, executes the 'whoami' command.\n",
            "    malicious_pickle = base64.b64encode(b\"cposix\\nsystem\\np0\\n(S'whoami'\\np1\\ntp2\\nRp3\\n.\")\n",
            "    print(\"\\n--- Triggering Insecure Deserialization ---\")\n",
            "    manager.load_user_profile(malicious_pickle)\n",
            "    \n",
            "    # Trigger Command Injection vulnerability\n",
            "    malicious_hostname = \"127.0.0.1; echo 'Command injection successful!'\"\n",
            "    print(\"\\n--- Triggering Command Injection ---\")\n",
            "    manager.run_system_check(malicious_hostname)\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "\n",
            "```\n",
            "\n",
            "Bugs Injected:\n",
            "\n",
            "[\n",
            "  {\n",
            "    \"type\": \"Security Vulnerability\",\n",
            "    \"line_number\": 32,\n",
            "    \"description\": \"Insecure Deserialization using `pickle.loads` on user-provided data. An attacker can craft a malicious payload that executes arbitrary code on the server when deserialized, leading to remote code execution.\"\n",
            "  },\n",
            "  {\n",
            "    \"type\": \"Security Vulnerability\",\n",
            "    \"line_number\": 39,\n",
            "    \"description\": \"Command Injection vulnerability due to using an f-string to build a system command with user-controlled input. An attacker can append arbitrary shell commands to the input (e.g., 'localhost; rm -rf /') to be executed by the operating system.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Provided code snippet for testing\n",
        "long_sample_code = \"\"\"import sqlite3\n",
        "import threading\n",
        "import time\n",
        "\n",
        "class UserManager:\n",
        "    def __init__(self, db_path=\"users.db\"):\n",
        "        self.conn = sqlite3.connect(db_path)\n",
        "        self.cursor = self.conn.cursor()\n",
        "        self.cache = {}\n",
        "\n",
        "    def add_user(self, username, password):\n",
        "        # Logic error: storing password in plain text\n",
        "        self.cursor.execute(f\"INSERT INTO users (name, password) VALUES ('{username}', '{password}')\")\n",
        "        self.conn.commit()\n",
        "\n",
        "    def get_user(self, username):\n",
        "        # Security vulnerability: SQL injection risk\n",
        "        query = f\"SELECT * FROM users WHERE name = '{username}'\"\n",
        "        self.cursor.execute(query)\n",
        "        return self.cursor.fetchall()\n",
        "\n",
        "    def cache_user(self, username):\n",
        "        # Potential memory leak: cache never cleared\n",
        "        user = self.get_user(username)\n",
        "        self.cache[username] = user\n",
        "\n",
        "def worker_task(manager, username):\n",
        "    # Concurrency bug: race condition on shared cache\n",
        "    for _ in range(1000):\n",
        "        manager.cache_user(username)\n",
        "\n",
        "def heavy_computation(n):\n",
        "    # Performance issue: inefficient recursion\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    return heavy_computation(n-1) + heavy_computation(n-2)\n",
        "\n",
        "def main():\n",
        "    manager = UserManager()\n",
        "    manager.add_user(\"Alice\", \"password123\")\n",
        "    manager.add_user(\"Bob\", \"hunter2\")\n",
        "\n",
        "    # Start multiple threads (race condition risk)\n",
        "    threads = []\n",
        "    for name in [\"Alice\", \"Bob\"]:\n",
        "        t = threading.Thread(target=worker_task, args=(manager, name))\n",
        "        threads.append(t)\n",
        "        t.start()\n",
        "\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "\n",
        "    # Trigger performance bottleneck\n",
        "    print(\"Fibonacci(30):\"), heavy_computation(30))\n",
        "\n",
        "    # Crash bug: division by zero\n",
        "    print(\"Divide:\", 10 / 0)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\"\"\"\n",
        "\n",
        "# 1. Initialize vector store and embeddings\n",
        "# This assumes initialize_vector_store_and_embeddings is already defined and working.\n",
        "embedding_model, vector_store = initialize_vector_store_and_embeddings()\n",
        "print(\"RAG system initialized.\")\n",
        "\n",
        "# 2. Load the new sample code into the vector store\n",
        "load_and_index_code([long_sample_code], embedding_model, vector_store)\n",
        "print(\"Long sample code loaded into vector store.\")\n",
        "\n",
        "# --- Test analyze_code ---\n",
        "print(\"\\n=== Testing analyze_code ===\")\n",
        "# query_analyze_long_code = \"Analyze the UserManager class and main function for all potential issues.\"\n",
        "query_analyze_long_code = \"Analyze the code for potential bugs, security risks, performance issues, and bestpractice violations.\"\n",
        "analysis_result_long = analyze_code(\n",
        "    query=query_analyze_long_code,\n",
        "    embedding_model=embedding_model,\n",
        "    vector_store=vector_store\n",
        ")\n",
        "print(\"\\n--- Analysis Result (long_sample_code) ---\\n\")\n",
        "print(json.dumps(analysis_result_long, indent=2))\n",
        "\n",
        "# --- Test get_code_metrics ---\n",
        "print(\"\\n=== Testing get_code_metrics ===\")\n",
        "# query_metrics_long_code = \"Provide code quality and security metrics for the UserManager class and related functions.\"\n",
        "query_metrics_long_code = \"Provide overall code quality, security metrics, bug density, and issue distribution.\"\n",
        "metrics_result_long = get_code_metrics(\n",
        "    query=query_metrics_long_code,\n",
        "    embedding_model=embedding_model,\n",
        "    vector_store=vector_store\n",
        ")\n",
        "print(\"\\n--- Metrics Result (long_sample_code) ---\\n\")\n",
        "print(json.dumps(metrics_result_long, indent=2))\n",
        "\n",
        "# --- Test inject_bugs ---\n",
        "print(\"\\n=== Testing inject_bugs ===\")\n",
        "# query_inject_bug_long_code = \"Inject a security vulnerability into the get_user function and a performance issue into heavy_computation.\"\n",
        "query_inject_bug_long_code = \"Inject bugs into the code and return details.\"\n",
        "bug_injection_result_long = inject_bugs(\n",
        "    query=query_inject_bug_long_code,\n",
        "    embedding_model=embedding_model,\n",
        "    vector_store=vector_store,\n",
        "    bug_type=\"Security Vulnerability\",\n",
        "    severity_level=5,\n",
        "    num_bugs=2\n",
        ")\n",
        "print(\"\\n--- Bug Injection Result (long_sample_code) ---\\n\")\n",
        "\n",
        "print(\"Buggy Code:\\n```python\\n\" + bug_injection_result_long['buggy_code'] + \"\\n```\")\n",
        "print(\"\\nBugs Injected:\\n\")\n",
        "print(json.dumps(bug_injection_result_long['bugs_injected'], indent=2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
